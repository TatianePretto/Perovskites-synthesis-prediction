{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9cd656",
   "metadata": {},
   "source": [
    "# Data Loading and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eaf60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from csv\n",
    "path = r'C:/Users/taty_/OneDrive/Área de Trabalho/Doutorado/Escrita artigo ML/Códigos github/Database Raw.csv'\n",
    "\n",
    "Perovskites = pd.read_csv(path, \n",
    "                          decimal = '.')\n",
    "\n",
    "#Perovskites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02828308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data-tracking columns (identify the origin of the observations)\n",
    "Perovskites = Perovskites.drop(['Articles', \n",
    "                                'DOI', \n",
    "                                'Diameter_from', \n",
    "                                'Bandgap_from'], \n",
    "                                axis=1)\n",
    "\n",
    "#Perovskites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de052631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variables that will not be used on this study (cathegorical variables that we will not apply one-hot encoder)\n",
    "Perovskites = Perovskites.drop(['Phosphine',\n",
    "                                'Phosphine_amount_mmol',\n",
    "                                'Amine','Carboxylic_acid',\n",
    "                                'Solvent_I',\n",
    "                                'Solvent_II'], \n",
    "                                axis=1)\n",
    "\n",
    "#Perovskites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the perovskite especification (we want a compound-agnostic model)\n",
    "Perovskites = Perovskites.drop(['Perovskite'], \n",
    "                               axis=1)\n",
    "\n",
    "#Perovskites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "Perovskites = Perovskites.drop([37,52,154, 56, 15, 65], \n",
    "                               axis=0, \n",
    "                               inplace=False)\n",
    "#Perovskites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bde18",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542308cd",
   "metadata": {},
   "source": [
    "### Pearson's Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99014d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plot libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1ecab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation plot shown in Support Information (FIGURE S1)\n",
    "heatmap = sns.heatmap(Perovskites.select_dtypes(include=np.number).corr(), \n",
    "                      vmin=-1, \n",
    "                      vmax=1, \n",
    "                      annot=False, \n",
    "                      cmap=sns.diverging_palette(20, 220, n=200),\n",
    "                      square=True)\n",
    "\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(),\n",
    "                       rotation=45,\n",
    "                       horizontalalignment='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove correlated variables (based on correlation plot available in the Support Information)\n",
    "Perovskites = Perovskites.drop(['Total_amount',\n",
    "                                'Tolerance_factor_old',\n",
    "                                'Growth_K'], \n",
    "                               axis=1)\n",
    "\n",
    "#Perovskites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced53b18",
   "metadata": {},
   "source": [
    "### SHAP Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random forest, metrics and shap libraries\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from hyperopt import hp, fmin, tpe, space_eval, Trials, atpe\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c64aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only numerical features for random forest training\n",
    "x_shap = Perovskites[['Tolerance_factor_new', \n",
    "                      'Temperature_K', \n",
    "                      'B2_amount_mmol',\\\n",
    "                      'A_amount_mmol', \n",
    "                      'Carboxylic_acid_amount_mmol', \\\n",
    "                      'S_I_amount_mL', \n",
    "                      'S_II_amount_mL', \n",
    "                      'Diameter_nm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the targets\n",
    "y_shap = Perovskites[['B1_amount_mmol',  \n",
    "                      'X_amount_mmol', \n",
    "                      'Time_min','Bandgap', \n",
    "                      'Amine_amount_mmol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f55474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying logarithmic transformation for features with wide numerical range\n",
    "x_shap['Diameter_nm'] = np.log10(x_shap[\"Diameter_nm\"])\n",
    "x_shap['B2_amount_mmol'] = np.log10(x_shap[\"B2_amount_mmol\"])\n",
    "x_shap['Temperature_K'] = np.log10(x_shap[\"Temperature_K\"])\n",
    "x_shap['Tolerance_factor_new'] = np.log10(x_shap[\"Tolerance_factor_new\"])\n",
    "\n",
    "y_shap['Time_min'] = np.log10(y_shap[\"Time_min\"])\n",
    "y_shap['Bandgap'] = np.log10(y_shap[\"Bandgap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bce9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test set split (75% training and 25% test)\n",
    "np.random.seed(100)\n",
    "\n",
    "X_train_shap, X_test_shap, y_train_shap, y_test_shap = train_test_split(x_shap, y_shap, test_size=0.25, random_state=25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperopt\n",
    "# Define the search space\n",
    "space = {\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False]),\n",
    "    'max_depth': hp.choice('max_depth', range(1, 1000)),\n",
    "    'max_features': hp.choice('max_features', [1.0, 'sqrt']),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 10)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 1000))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining cross-validation settings\n",
    "cv = KFold(n_splits=5, \n",
    "           random_state=25, \n",
    "           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective(params):\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    scores = cross_val_score(rf, X_train_shap, y_train_shap, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean())  # Negative mean squared error to minimize\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, \n",
    "            space=space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=100, \n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "best_params = space_eval(space, best)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a Random Forest regressor with the best hyperparameters\n",
    "rf_feat_select = RandomForestRegressor(**best_params)\n",
    "rf_feat_select.fit(X_train_shap, y_train_shap)\n",
    "scores = cross_val_score(rf_feat_select, \n",
    "                         X_train_shap, \n",
    "                         y_train_shap, \n",
    "                         cv=cv, \n",
    "                         scoring='neg_root_mean_squared_error')\n",
    "scores*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f879e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on train and test set\n",
    "y_pred_feat_select = rf_feat_select.predict(X_test_shap)\n",
    "y_pred_train_feat_select = rf_feat_select.predict(X_train_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics \n",
    "MAE_train_feat_select = pd.DataFrame(mean_absolute_error(y_train_shap, y_pred_train_feat_select, multioutput='raw_values'))\n",
    "RMSE_train_feat_select = pd.DataFrame(np.sqrt(mean_squared_error(y_train_shap, y_pred_train_feat_select, multioutput='raw_values')))\n",
    "R2_train_feat_select = pd.DataFrame(r2_score(y_train_shap, y_pred_train_feat_select, multioutput='raw_values'))\n",
    "\n",
    "train_metrics_feat_select = pd.concat([MAE_train_feat_select, RMSE_train_feat_select, R2_train_feat_select], axis='columns')\n",
    "train_metrics_feat_select.columns = ['MAE_train_FS', 'RMSE_train_FS', 'R2_train_FS']\n",
    "\n",
    "print(train_metrics_feat_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be1e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metrics\n",
    "MAE_test_feat_select = pd.DataFrame(mean_absolute_error(y_test_shap, y_pred_feat_select, multioutput='raw_values'))\n",
    "RMSE_test_feat_select = pd.DataFrame(np.sqrt(mean_squared_error(y_test_shap, y_pred_feat_select, multioutput='raw_values')))\n",
    "R2_test_feat_select = pd.DataFrame(r2_score(y_test_shap, y_pred_feat_select, multioutput='raw_values'))\n",
    "\n",
    "test_metrics_feat_select = pd.concat([MAE_test_feat_select, RMSE_test_feat_select, R2_test_feat_select], axis='columns')\n",
    "test_metrics_feat_select.columns = ['MAE_test_FS', 'RMSE_test_FS', 'R2_test_FS']\n",
    "\n",
    "print(test_metrics_feat_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unite train and test performance dataframes (FIGURE S2-a)\n",
    "df_unified_fs = pd.concat([train_metrics_feat_select, test_metrics_feat_select], axis=1)\n",
    "df_unified_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c135b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap plot para o modelo geral\n",
    "explainer = shap.TreeExplainer(rf_feat_select, data = X_train_shap, link = \"identity\")\n",
    "shap_values_rf = explainer.shap_values(X_train_shap, check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0fb68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use index positions as feature names\n",
    "feature_names = X_train_shap.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d760029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up the SHAP values across all classes\n",
    "shap_values_combined = np.sum(shap_values_rf, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90863efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single SHAP summary plot for all classes\n",
    "shap.summary_plot(shap_values_combined, X_train_shap, feature_names=feature_names, show=False)\n",
    "\n",
    "# Display the plot (FIGURE S2-a)\n",
    "shap.initjs()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01591ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature removal based on shap feature importance\n",
    "Perovskites = Perovskites.drop(['S_II_amount_mL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-evaluation of feature importance after removal\n",
    "# Selecting only numerical features for random forest training\n",
    "x_shap = Perovskites[['Tolerance_factor_new', 'Temperature_K', 'B2_amount_mmol',\\\n",
    "                    'A_amount_mmol', 'Carboxylic_acid_amount_mmol', \\\n",
    "                    'S_I_amount_mL', 'Diameter_nm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340202c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying logarithmic transformation for features with wide numerical range\n",
    "x_shap['Diameter_nm'] = np.log10(x_shap[\"Diameter_nm\"])\n",
    "x_shap['B2_amount_mmol'] = np.log10(x_shap[\"B2_amount_mmol\"])\n",
    "x_shap['Temperature_K'] = np.log10(x_shap[\"Temperature_K\"])\n",
    "x_shap['Tolerance_factor_new'] = np.log10(x_shap[\"Tolerance_factor_new\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9773e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test set split (75% training and 25% test)\n",
    "np.random.seed(100)\n",
    "X_train_shap, X_test_shap, y_train_shap, y_test_shap = train_test_split(x_shap, y_shap, test_size=0.25, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd08d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperopt\n",
    "# Define the search space\n",
    "space = {\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False]),\n",
    "    'max_depth': hp.choice('max_depth', range(1, 1000)),\n",
    "    'max_features': hp.choice('max_features', [1.0, 'sqrt']),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 10)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 1000))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining cross-validation settings\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e4478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6290c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "best_params = space_eval(space, best)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0039911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a Random Forest regressor with the best hyperparameters\n",
    "rf_feat_select = RandomForestRegressor(**best_params)\n",
    "rf_feat_select.fit(X_train_shap, y_train_shap)\n",
    "scores = cross_val_score(rf_feat_select, X_train_shap, y_train_shap, cv=cv, scoring='neg_root_mean_squared_error')\n",
    "scores*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shap plot para o modelo geral\n",
    "explainer = shap.TreeExplainer(rf_feat_select, data = X_train_shap, link = \"identity\")\n",
    "shap_values_rf = explainer.shap_values(X_train_shap, check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use index positions as feature names\n",
    "feature_names = X_train_shap.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83af649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up the SHAP values across all classes\n",
    "shap_values_combined = np.sum(shap_values_rf, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single SHAP summary plot for all classes\n",
    "shap.summary_plot(shap_values_combined, X_train_shap, feature_names=feature_names, show=False)\n",
    "\n",
    "# Display the plot (FIGURE S2-b)\n",
    "shap.initjs()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2865d5a4",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5269557",
   "metadata": {},
   "source": [
    "### One-hot encoding to categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying one hot encoding to categorical variables\n",
    "Perovskites_encoded = pd.get_dummies(Perovskites, columns=['A_source','B1_source', 'B2_source', 'X_source'], dtype = int)\n",
    "#print(Perovskites_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying logarithmic transformation to variables with high range \n",
    "Perovskites_encoded['Diameter_nm'] = np.log10(Perovskites_encoded['Diameter_nm'])\n",
    "Perovskites_encoded['Time_min'] = np.log10(Perovskites_encoded['Time_min'])\n",
    "Perovskites_encoded['B2_amount_mmol'] = np.log10(Perovskites_encoded['B2_amount_mmol'])\n",
    "Perovskites_encoded['Temperature_K'] = np.log10(Perovskites_encoded['Temperature_K'])\n",
    "Perovskites_encoded['Bandgap'] = np.log10(Perovskites_encoded['Bandgap'])\n",
    "Perovskites_encoded['Tolerance_factor_new'] = np.log10(Perovskites_encoded['Tolerance_factor_new'])\n",
    "#Perovskites_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: predictors (x) and targets (y)\n",
    "x = Perovskites_encoded.drop(['B1_amount_mmol', 'X_amount_mmol', 'Time_min', 'Bandgap', 'Amine_amount_mmol'],\n",
    "                             axis=1)\n",
    "y = Perovskites_encoded[[ 'B1_amount_mmol',  'X_amount_mmol', 'Time_min','Bandgap', 'Amine_amount_mmol']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239d2a37",
   "metadata": {},
   "source": [
    "### Pre-processed data with selected features ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03441396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features (predictors) dataset\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets dataset\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split (75% training and 25% test)\n",
    "np.random.seed(100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=25) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fff5df",
   "metadata": {},
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc8ecb1",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced79a9b",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e62768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import decision tree library\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c780e",
   "metadata": {},
   "source": [
    "#### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45985d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(1, 1000)),\n",
    "    'max_features': hp.choice('max_features', [1.0, 'sqrt']),\n",
    "    'max_leaf_nodes': hp.choice('max_leaf_nodes', range(2, 500)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 10)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'min_weight_fraction_leaf': hp.choice('min_weight_fraction_leaf', [0.1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining cross-validation parameters\n",
    "cv = KFold(n_splits=5, random_state=25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0688c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective(params):\n",
    "    dt_ho = DecisionTreeRegressor(**params)\n",
    "    scores = cross_val_score(dt_ho, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean())  # Negative mean squared error to minimize\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16af9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3631134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "best_params_ho = space_eval(space, best)\n",
    "best_params_ho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1345d8",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the grid\n",
    "param_grid = {\n",
    "                   'max_depth': range(2,500,50),\n",
    "                   'max_features': ('auto', 'sqrt'),\n",
    "                   'max_leaf_nodes': range(2,500,50),\n",
    "                   'min_samples_leaf': range(2,10),\n",
    "                   'min_weight_fraction_leaf': [0.1],\n",
    "                   'min_samples_split': range(2,10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44746ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "dt_gs = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07acbb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = dt_gs, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on train and test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "y_pred_train = grid_search.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb601f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adee7b65",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation (Hyperopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37757c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree regressor with the best hyperparameters\n",
    "dt_ho = DecisionTreeRegressor(**best_params_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abee5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the cross-validation scores\n",
    "scores = cross_val_score(dt_ho, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "scores*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Decision Tree regressor\n",
    "dt_ho.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8affe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "y_pred_ho = dt_ho.predict(X_test)\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14dc2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on train set\n",
    "y_pred_train_ho = dt_ho.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics on train dataset\n",
    "MAE_train = pd.DataFrame(metrics.mean_absolute_error(y_train, y_pred_train_ho, multioutput='raw_values'))\n",
    "RMSE_train = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_train, y_pred_train_ho, multioutput='raw_values')))\n",
    "R2_train = pd.DataFrame(r2_score(y_train, y_pred_train_ho, multioutput='raw_values'))\n",
    "\n",
    "train_metrics_dt = pd.concat([MAE_train, RMSE_train, R2_train], axis='columns')\n",
    "train_metrics_dt.columns = ['MAE_train_HO','RMSE_train_HO','R2_train_HO']\n",
    "print(train_metrics_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics on test dataset\n",
    "MAE_test_dt = pd.DataFrame(metrics.mean_absolute_error(y_test, y_pred_ho, multioutput='raw_values'))\n",
    "RMSE_test_dt = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_test, y_pred_ho, multioutput='raw_values')))\n",
    "R2_test_dt =pd.DataFrame(r2_score(y_test, y_pred_ho, multioutput='raw_values'))\n",
    "\n",
    "test_metrics_dt = pd.concat([MAE_test_dt, RMSE_test_dt, R2_test_dt], axis='columns')\n",
    "test_metrics_dt.columns = ['MAE_test_HO', 'RMSE_test_HO','R2_test_HO']\n",
    "print(test_metrics_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34423db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unite train and test performance dataframes \n",
    "df_unified_ho = pd.concat([train_metrics_dt, test_metrics_dt], axis=1)\n",
    "df_unified_ho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32b3c09",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the cross-validation scores\n",
    "scores = cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "scores*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Decision Tree regressor\n",
    "grid_search.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0bc942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on train set\n",
    "y_pred_train = grid_search.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc26702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics on train dataset\n",
    "MAE_train = pd.DataFrame(metrics.mean_absolute_error(y_train, y_pred_train, multioutput='raw_values'))\n",
    "RMSE_train = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_train, y_pred_train, multioutput='raw_values')))\n",
    "R2_train = pd.DataFrame(r2_score(y_train, y_pred_train, multioutput='raw_values'))\n",
    "\n",
    "train_metrics_dt = pd.concat([MAE_train, RMSE_train, R2_train], axis='columns')\n",
    "train_metrics_dt.columns = ['MAE_train_GS','RMSE_train_GS','R2_train_GS']\n",
    "print(train_metrics_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230db14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics on test dataset\n",
    "MAE_test_dt = pd.DataFrame(metrics.mean_absolute_error(y_test, y_pred, multioutput='raw_values'))\n",
    "RMSE_test_dt = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_test, y_pred, multioutput='raw_values')))\n",
    "R2_test_dt = pd.DataFrame(r2_score(y_test, y_pred, multioutput='raw_values'))\n",
    "\n",
    "test_metrics_dt = pd.concat([MAE_test_dt, RMSE_test_dt, R2_test_dt], axis='columns')\n",
    "test_metrics_dt.columns = ['MAE_test_GS', 'RMSE_test_GS','R2_test_GS']\n",
    "print(test_metrics_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unite train and test performance dataframes \n",
    "df_unified_gs = pd.concat([train_metrics_dt, test_metrics_dt], axis=1)\n",
    "#df_unified_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unite performance dataframes from hyperopt and grid search (TABLE S4 - Decision Trees)\n",
    "df_unified_dt = pd.concat([df_unified_ho, df_unified_gs], axis=1)\n",
    "df_unified_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5834bddf",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store multiple figure and figure names\n",
    "file_names = []\n",
    "figs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e3949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining color palette\n",
    "colors = sns.diverging_palette(20, 220, n=200)\n",
    "cor_teste = 20\n",
    "cor_treino = 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining number of columns\n",
    "num_cols = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to plot parity plot for all targets (FIGURE 4 - Decision Trees)\n",
    "for i in range(num_cols):\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    target = y_train.columns[i]\n",
    "    \n",
    "    # Scatter plot for predictions on test data\n",
    "    ax.scatter(y_test.iloc[:, i], y_pred_ho[:, i], color=colors[cor_teste], label='Test Set', s=30)\n",
    "    \n",
    "    # Scatter plot for predictions on training data\n",
    "    ax.scatter(y_train.iloc[:, i], y_pred_train_ho[:, i], color=colors[cor_treino], label='Train Set', s=30)\n",
    "    \n",
    "    # Diagonal reference line\n",
    "    ax.plot([min(y_test.iloc[:, i].values), max(y_test.iloc[:, i].values)],\n",
    "            [min(y_test.iloc[:, i].values), max(y_test.iloc[:, i].values)],\n",
    "            color='black', linestyle='--')\n",
    "    \n",
    "    # Calculating validation metrics\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred_ho[:, i])\n",
    "    mae = mean_absolute_error(y_test.iloc[:, i], y_pred_ho[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred_ho[:, i]))\n",
    "    \n",
    "    # Add validation metrics to the plot\n",
    "    ax.text(0.04, 0.65, f'R²: {r2:.2f}\\nMAE: {mae:.2f}\\nRMSE: {rmse:.2f}', transform=ax.transAxes, fontsize=18)\n",
    "    \n",
    "    # Defining y axis label\n",
    "    ax.set_ylabel('Predicted values', fontsize=22)\n",
    "        \n",
    "    # Defining x axis label\n",
    "    ax.set_xlabel('True Values', fontsize=22)\n",
    "\n",
    "    # Changing axis character size\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        \n",
    "    # Name of the target\n",
    "    ax.set_title(f'{target}', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    # Positioning legend outside the plot\n",
    "    fig.legend(loc='center left', bbox_to_anchor=(0.95, 0.5),frameon=False, fontsize=14)\n",
    "    \n",
    "    # Resolution adjust\n",
    "    fig.set_dpi(500)\n",
    "\n",
    "    # Add figure to list\n",
    "    figs.append(fig)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f000639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap plot for general model (combined targets)\n",
    "explainer = shap.TreeExplainer(dt_ho, data = X_train, link = \"identity\")\n",
    "shap_values_dt = explainer.shap_values(X_train, check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5492321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use index positions as feature names\n",
    "feature_names = X_train.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up the SHAP values across all classes\n",
    "shap_values_combined = np.sum(shap_values_dt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2105f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single SHAP summary plot for all classes\n",
    "shap.summary_plot(shap_values_combined, X_train, feature_names=feature_names, show=False)\n",
    "\n",
    "# Display the plot (FIGURE 6-a)\n",
    "shap.initjs()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac535ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP variable importance per feature x per target\n",
    "class_names = y.columns\n",
    "shap.summary_plot(shap_values_dt, X_train, class_names=class_names, max_display=10, show=False)\n",
    "\n",
    "# Display the plot (FIGURE 6-a)\n",
    "shap.initjs()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d881e7",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf0159",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ff3b7",
   "metadata": {},
   "source": [
    "#### Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'bootstrap': hp.choice('bootstrap', [True, False]),\n",
    "    'max_depth': hp.choice('max_depth', range(1, 1000)),\n",
    "    'max_features': hp.choice('max_features', [1.0, 'sqrt', 'log2']),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 10)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 10)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 1000))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b915d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining cross-validation parameters\n",
    "cv = KFold(n_splits = 10, random_state = 25, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6de1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective(params):\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse = np.sqrt(-scores.mean())  # Negative mean squared error to minimize\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec0380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hyperparameter optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 200, trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cebc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "best_params = space_eval(space, best)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59641e62",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing ranges for hyperparameters\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': range(10,500,50),\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': range(1,31,5),\n",
    "    'min_samples_split': range(1,21,5),\n",
    "    'n_estimators': range(100,500,50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339619b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbd766",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation (hyperopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34fce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest regressor with the best hyperparameters - hyperopt\n",
    "rf = RandomForestRegressor(random_state=123, **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45bcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the cross-validation scores\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "scores*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Random Forest regressor\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on train and test set\n",
    "y_pred_ho = rf.predict(X_test)\n",
    "y_pred_train_ho = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b8b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "MAE_train_rf = pd.DataFrame(mean_absolute_error(y_train, y_pred_train_ho, multioutput='raw_values'))\n",
    "RMSE_train_rf = pd.DataFrame(np.sqrt(mean_squared_error(y_train, y_pred_train_ho, multioutput='raw_values')))\n",
    "R2_train_rf = pd.DataFrame(r2_score(y_train, y_pred_train_ho, multioutput='raw_values'))\n",
    "\n",
    "train_metrics_rf = pd.concat([MAE_train_rf, RMSE_train_rf, R2_train_rf], axis='columns')\n",
    "train_metrics_rf.columns = ['MAE_train_HO', 'RMSE_train_HO', 'R2_train_HO']\n",
    "\n",
    "print(train_metrics_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2344865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metrics\n",
    "MAE_test_rf = pd.DataFrame(mean_absolute_error(y_test, y_pred_ho, multioutput='raw_values'))\n",
    "RMSE_test_rf = pd.DataFrame(np.sqrt(mean_squared_error(y_test, y_pred_ho, multioutput='raw_values')))\n",
    "R2_test_rf = pd.DataFrame(r2_score(y_test, y_pred_ho, multioutput='raw_values'))\n",
    "\n",
    "test_metrics_rf = pd.concat([MAE_test_rf, RMSE_test_rf, R2_test_rf], axis='columns')\n",
    "test_metrics_rf.columns = ['MAE_test_HO', 'RMSE_test_HO', 'R2_test_HO']\n",
    "\n",
    "print(test_metrics_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250a847",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Unite train and test performance dataframes \n",
    "df_unified_ho = pd.concat([train_metrics_rf, test_metrics_rf], axis=1)\n",
    "df_unified_ho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbd90f",
   "metadata": {},
   "source": [
    "#### Performance evaluation (hyperopt): Parity Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812039ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store multiple figure and figure names\n",
    "file_names = []\n",
    "figs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc183b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining color palette\n",
    "colors = sns.diverging_palette(20, 220, n=200)\n",
    "cor_teste = 20\n",
    "cor_treino = 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining number of columns\n",
    "num_cols = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eecdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to plot parity plot for all targets (FIGURE 4 - Decision Trees)\n",
    "for i in range(num_cols):\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    target = y_train.columns[i]\n",
    "    \n",
    "    # Scatter plot for predictions on test data\n",
    "    ax.scatter(y_test.iloc[:, i], y_pred_ho[:, i], color=colors[cor_teste], label='Test Set', s=30)\n",
    "    \n",
    "    # Scatter plot for predictions on training data\n",
    "    ax.scatter(y_train.iloc[:, i], y_pred_train_ho[:, i], color=colors[cor_treino], label='Train Set', s=30)\n",
    "    \n",
    "    # Diagonal reference line\n",
    "    ax.plot([min(y_test.iloc[:, i].values), max(y_test.iloc[:, i].values)],\n",
    "            [min(y_test.iloc[:, i].values), max(y_test.iloc[:, i].values)],\n",
    "            color='black', linestyle='--')\n",
    "    \n",
    "    # Calculating validation metrics\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred_ho[:, i])\n",
    "    mae = mean_absolute_error(y_test.iloc[:, i], y_pred_ho[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred_ho[:, i]))\n",
    "    \n",
    "    # Add validation metrics to the plot\n",
    "    ax.text(0.04, 0.65, f'R²: {r2:.2f}\\nMAE: {mae:.2f}\\nRMSE: {rmse:.2f}', transform=ax.transAxes, fontsize=18)\n",
    "    \n",
    "    # Defining y axis label\n",
    "    ax.set_ylabel('Predicted values', fontsize=22)\n",
    "        \n",
    "    # Defining x axis label\n",
    "    ax.set_xlabel('True Values', fontsize=22)\n",
    "\n",
    "    # Changing axis character size\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        \n",
    "    # Name of the target\n",
    "    ax.set_title(f'{target}', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    # Positioning legend outside the plot\n",
    "    fig.legend(loc='center left', bbox_to_anchor=(0.95, 0.5),frameon=False, fontsize=18)\n",
    "    \n",
    "    # Resolution adjust\n",
    "    fig.set_dpi(500)\n",
    "\n",
    "    # Add figure to list\n",
    "    figs.append(fig)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d599681b",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the cross-validation scores\n",
    "scores = cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "scores*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9740cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Decision Tree regressor\n",
    "grid_search.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf7acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfdc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on train set\n",
    "y_pred_train = grid_search.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics on train dataset\n",
    "MAE_train = pd.DataFrame(metrics.mean_absolute_error(y_train, y_pred_train, multioutput='raw_values'))\n",
    "RMSE_train = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_train, y_pred_train, multioutput='raw_values')))\n",
    "R2_train = pd.DataFrame(r2_score(y_train, y_pred_train, multioutput='raw_values'))\n",
    "\n",
    "train_metrics_rf = pd.concat([MAE_train, RMSE_train, R2_train], axis='columns')\n",
    "train_metrics_rf.columns = ['MAE_train_GS','RMSE_train_GS','R2_train_GS']\n",
    "print(train_metrics_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics on test dataset\n",
    "MAE_test_rf = pd.DataFrame(metrics.mean_absolute_error(y_test, y_pred, multioutput='raw_values'))\n",
    "RMSE_test_rf = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_test, y_pred, multioutput='raw_values')))\n",
    "R2_test_rf = pd.DataFrame(r2_score(y_test, y_pred, multioutput='raw_values'))\n",
    "\n",
    "test_metrics_rf = pd.concat([MAE_test_rf, RMSE_test_rf, R2_test_rf], axis='columns')\n",
    "test_metrics_rf.columns = ['MAE_test_GS', 'RMSE_test_GS','R2_test_GS']\n",
    "print(test_metrics_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unite train and test performance dataframes \n",
    "df_unified_gs = pd.concat([train_metrics_rf, test_metrics_rf], axis=1)\n",
    "df_unified_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83fac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unite performance dataframes from hyperopt and grid search (Table 1)\n",
    "df_unified_rf = pd.concat([df_unified_ho, df_unified_gs], axis=1)\n",
    "df_unified_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2185779",
   "metadata": {},
   "source": [
    "#### Feature importance: SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_rf2 = shap.TreeExplainer(model = rf, data = X_train, link = 'identity')\n",
    "shap_values_rf2 = e_rf2.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e241ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use index positions as feature names\n",
    "feature_names = X_train.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up the SHAP values across all classes\n",
    "shap_values_combined = np.sum(shap_values_rf2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a6f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single SHAP summary plot for all classes\n",
    "shap.summary_plot(shap_values_combined, X_train, max_display=10, feature_names=feature_names, show=False)\n",
    "\n",
    "# Display the plot (FIGURE 6-b)\n",
    "shap.initjs()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bar plot shap - per feature x per target\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_rf = shap.TreeExplainer(rf)\n",
    "shap_values_rf = e_rf.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e59e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP variable importance per feature x per target\n",
    "class_names = y.columns\n",
    "shap.summary_plot(shap_values_rf, X_train, class_names=class_names, max_display=10, show=False)\n",
    "\n",
    "# Display the plot (FIGURE 6-b)\n",
    "shap.initjs()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP plot separated for each target (Figure S3)\n",
    "\n",
    "e_rf = shap.TreeExplainer(rf)\n",
    "shap_values_rf = e_rf.shap_values(X_train)\n",
    "\n",
    "for i, shap_values_target in enumerate(shap_values_rf):\n",
    "    target_name = class_names[i]\n",
    "    shap.summary_plot(shap_values_target, X_train, max_display=10, show=False)\n",
    "                      \n",
    "    # Display the plot for the current target\n",
    "    shap.initjs()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c29698",
   "metadata": {},
   "source": [
    "#### Performance evaluation: Residual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb698b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining color palette\n",
    "colors = sns.diverging_palette(20, 220, n=200)\n",
    "cor_pontos = 20\n",
    "cor_reta = 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb959364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual calculation and convertion to dataframe\n",
    "y_pred_rf_ho = pd.DataFrame(y_pred_ho, columns=y_test.columns)\n",
    "y_pred_rf_gs = pd.DataFrame(y_pred, columns=y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining y_pred indexes\n",
    "y_pred_rf_ho.reset_index(drop=True, inplace=True)\n",
    "y_pred_rf_gs.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc142bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store multiple figure and figure names\n",
    "file_names = []\n",
    "figs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee161d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if test and pred dataframes are the same size (FIGURE 7/FIGURE S4-b)\n",
    "if len(y_test) == len(y_pred_rf_ho):\n",
    "    # Residual calculation\n",
    "    residuals = y_test - y_pred_rf_ho\n",
    "    \n",
    "    # Loop to plot residual plot for all targets\n",
    "    for column in residuals.columns:\n",
    "        # Create figure and axis\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        # get residual values as lists (iterable)\n",
    "        predicted_values = y_pred_rf_ho[column].values.tolist()\n",
    "        residual_values = residuals[column].values.tolist()\n",
    "\n",
    "        # Residual Plot\n",
    "        ax.scatter(predicted_values, residual_values, color=colors[cor_pontos], s=50)\n",
    "        ax.axhline(y=0, color=colors[cor_reta], linestyle='-', linewidth=3)\n",
    "        ax.set_xlabel('Predicted Values', fontsize=22)\n",
    "        ax.set_ylabel('Residuals', fontsize=22)\n",
    "        ax.set_title(column, fontsize=22)\n",
    "\n",
    "        # Resolution adjust\n",
    "        fig.set_dpi(500)\n",
    "\n",
    "        # Residuals Statistics\n",
    "        residual_mae = mean_absolute_error(y_test[column], y_pred_rf_ho[column])\n",
    "        residual_rmse = np.sqrt(mean_squared_error(y_test[column], y_pred_rf_ho[column]))\n",
    "        residual_r2 = r2_score(y_test[column], y_pred_rf_ho[column])\n",
    "\n",
    "        # Add validation metrics to the plot\n",
    "        text = f\"MAE: {residual_mae:.4f}\\nRMSE: {residual_rmse:.4f}\\nR2 Score: {residual_r2:.4f}\"\n",
    "        ax.text(0.05, 0.95, text, transform=ax.transAxes, fontsize=16, verticalalignment='top')\n",
    "\n",
    "        # Add figure to list\n",
    "        figs.append(fig)\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9a295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if test and pred dataframes are the same size (FIGURE S4-a)\n",
    "if len(y_test) == len(y_pred_rf_gs):\n",
    "    # Residual calculation\n",
    "    residuals = y_test - y_pred_rf_gs\n",
    "    \n",
    "    # Loop to plot residual plot for all targets\n",
    "    for column in residuals.columns:\n",
    "        # Create figure and axis\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        # get residual values as lists (iterable)\n",
    "        predicted_values = y_pred_rf_gs[column].values.tolist()\n",
    "        residual_values = residuals[column].values.tolist()\n",
    "\n",
    "        # Residual Plot\n",
    "        ax.scatter(predicted_values, residual_values, color=colors[cor_pontos], s=50)\n",
    "        ax.axhline(y=0, color=colors[cor_reta], linestyle='-', linewidth=3)\n",
    "        ax.set_xlabel('Predicted Values', fontsize=22)\n",
    "        ax.set_ylabel('Residuals', fontsize=22)\n",
    "        ax.set_title(column, fontsize=22)\n",
    "\n",
    "        # Resolution adjust\n",
    "        fig.set_dpi(500)\n",
    "\n",
    "        # Residuals Statistics\n",
    "        residual_mae = mean_absolute_error(y_test[column], y_pred_rf_gs[column])\n",
    "        residual_rmse = np.sqrt(mean_squared_error(y_test[column], y_pred_rf_gs[column]))\n",
    "        residual_r2 = r2_score(y_test[column], y_pred_rf_gs[column])\n",
    "\n",
    "        # Add validation metrics to the plot\n",
    "        text = f\"MAE: {residual_mae:.4f}\\nRMSE: {residual_rmse:.4f}\\nR2 Score: {residual_r2:.4f}\"\n",
    "        ax.text(0.05, 0.95, text, transform=ax.transAxes, fontsize=16, verticalalignment='top')\n",
    "\n",
    "        # Add figure to list\n",
    "        figs.append(fig)\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7783f34e",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00868a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neural networks libraries\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random as python_random\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f33612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "def reset_seeds():\n",
    "   np.random.seed(9) \n",
    "   python_random.seed(9)\n",
    "   tf.random.set_seed(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96267c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling for neural network training\n",
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset seed value\n",
    "reset_seeds() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37439d",
   "metadata": {},
   "source": [
    "Hyperparameter Optimization - Using One-Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e3313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "def create_model(units1, units2, units3):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units1, input_dim=76, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(units2, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(units3, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(5))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440bdce9",
   "metadata": {},
   "source": [
    "Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327d79ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the objective function\n",
    "def objective(params):\n",
    "    units1 = params['units1']\n",
    "    units2 = params['units2']\n",
    "    units3 = params['units3']\n",
    "    epochs = params['epochs']\n",
    "\n",
    "    # Model fitting and prediction using cross-validation\n",
    "    model = KerasRegressor(build_fn=lambda: create_model(units1, units2, units3), epochs=epochs, batch_size=32, verbose=0)\n",
    "    rkf = KFold(n_splits=5, random_state=25, shuffle=True)\n",
    "    \n",
    "    # Final model fitting on train data\n",
    "    final_model = create_model(units1, units2, units3)\n",
    "    final_model.fit(X_train_norm, y_train, verbose=0, epochs=epochs, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Prediction on train and test datasets\n",
    "    y_pred_train_ho_he = cross_val_predict(model, X_train_norm, y_train, cv=rkf)\n",
    "    y_pred_ho_he = final_model.predict(X_test_norm)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1470cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search space\n",
    "space = {\n",
    "    'units1': hp.choice('units1', [100, 200, 250]),\n",
    "    'units2': hp.choice('units2', [100, 150, 200]),\n",
    "    'units3': hp.choice('units3', [50, 80]),\n",
    "    'epochs': hp.choice('epochs', [100, 150])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of results\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9931827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best hyperparameters values\n",
    "best_values = space_eval(space, best)\n",
    "print(best_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c4109",
   "metadata": {},
   "source": [
    "Final model - best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87907d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the function to create the model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(250, input_dim=76, activation='relu'))\n",
    "    model.add(Dense(150, activation='relu'))\n",
    "    model.add(Dense(80, activation='relu'))\n",
    "    model.add(Dense(5))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd088e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the KerasRegressor model\n",
    "model = KerasRegressor(build_fn=create_model, epochs=100, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72187a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting and prediction using cross-validation\n",
    "rkf = KFold(n_splits=5, random_state=25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model fitting on all training data\n",
    "final_model = create_model()\n",
    "final_model.fit(X_train_norm, \n",
    "                y_train, \n",
    "                verbose=1, \n",
    "                epochs=100, \n",
    "                batch_size=32, \n",
    "                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e183cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48957e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on train and test set\n",
    "y_pred_train_nn_he = cross_val_predict(model, X_train_norm, y_train, cv=rkf)\n",
    "y_pred_nn_he = final_model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ae0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train metrics\n",
    "MAE_train = pd.DataFrame(metrics.mean_absolute_error(y_train, y_pred_train_nn_he, multioutput='raw_values'))\n",
    "RMSE_train = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_train, y_pred_train_nn_he, multioutput='raw_values')))\n",
    "R2_train = pd.DataFrame(r2_score(y_train, y_pred_train_nn_he, multioutput='raw_values'))\n",
    "\n",
    "train_metrics_nn = pd.concat([MAE_train,  RMSE_train, R2_train], axis='columns')\n",
    "train_metrics_nn.columns = ['MAE_train', 'RMSE_train','R2_train']\n",
    "print(train_metrics_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test metrics\n",
    "MAE_test_nn = pd.DataFrame(metrics.mean_absolute_error(y_test, y_pred_nn_he, multioutput='raw_values'))\n",
    "RMSE_test_nn = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_test, y_pred_nn_he, multioutput='raw_values')))\n",
    "R2_test_nn = pd.DataFrame(r2_score(y_test, y_pred_nn_he, multioutput='raw_values'))\n",
    "\n",
    "test_metrics_nn = pd.concat([MAE_test_nn, RMSE_test_nn, R2_test_nn], axis='columns')\n",
    "test_metrics_nn.columns = ['MAE_test','RMSE_test','R2_test']\n",
    "print(test_metrics_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924b2f43",
   "metadata": {},
   "source": [
    "Optimization with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c47c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameter optimization using GridSearch\n",
    "def create_model(hidden_layer1=200, hidden_layer2=150, hidden_layer3=80):\n",
    "    reset_seeds()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer1, input_dim=76, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(hidden_layer2, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(hidden_layer3, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(5))\n",
    "    model.compile(loss ='mae', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede4d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the KerasRegressor model\n",
    "model = KerasRegressor(build_fn=create_model, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for neural network\n",
    "param_grid = {\n",
    "    'model__hidden_layer1': [100, 200, 20],\n",
    "    'model__hidden_layer2': [50, 150, 30],\n",
    "    'model__hidden_layer3': [30, 80, 20],\n",
    "    'epochs': [50, 200, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for optimal hyperparameters using cross-validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_absolute_error', cv=5)\n",
    "grid_result = grid.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea648e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best hyperparameters values\n",
    "print(\"Best hyperparameters: \", grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc3520",
   "metadata": {},
   "source": [
    "Optimized model - GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model with optimized hyperparameters\n",
    "def create_model(hidden_layer1=200, hidden_layer2=150, hidden_layer3=80):\n",
    "    reset_seeds()\n",
    "    model = Sequential()\n",
    "    model.add(Dense((20), input_dim=76, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(150, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(20, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(5))\n",
    "    model.compile(loss ='mae', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4141f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the neural network\n",
    "model = KerasRegressor(build_fn=create_model, verbose=False)\n",
    "history = model.fit(X_train_norm, y_train, verbose = 'auto',epochs = 200, shuffle=False, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71378ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on train and test sets\n",
    "y_pred_nn_gs=model.predict(X_test_norm)\n",
    "y_pred_train_nn_gs=model.predict(X_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10570dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train metrics\n",
    "MAE_train = pd.DataFrame(metrics.mean_absolute_error(y_train, y_pred_train_nn_gs, multioutput='raw_values'))\n",
    "RMSE_train = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_train, y_pred_train_nn_gs, multioutput='raw_values')))\n",
    "R2_train = pd.DataFrame(r2_score(y_train, y_pred_train_nn_gs, multioutput='raw_values'))\n",
    "\n",
    "train_metrics_nn_gs = pd.concat([MAE_train,  RMSE_train, R2_train], axis='columns')\n",
    "train_metrics_nn_gs.columns = ['MAE_train', 'RMSE_train','R2_train']\n",
    "print(train_metrics_nn_gs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test metrics\n",
    "MAE_test= pd.DataFrame(metrics.mean_absolute_error(y_test, y_pred_nn_gs, multioutput='raw_values'))\n",
    "RMSE_test = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_test, y_pred_nn_gs, multioutput='raw_values')))\n",
    "R2_test =pd.DataFrame(r2_score(y_test, y_pred_nn_gs, multioutput='raw_values'))\n",
    "\n",
    "test_metrics_nn_gs = pd.concat([MAE_test, RMSE_test, R2_test], axis='columns')\n",
    "test_metrics_nn_gs.columns = ['MAE_test','RMSE_test','R2_test']\n",
    "print(test_metrics_nn_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c108e",
   "metadata": {},
   "source": [
    "Without One-Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numeric columns\n",
    "numeric_columns = Perovskites.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Create a new dataframe with the numeric columns.\n",
    "Perovskites_num = Perovskites[numeric_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce80c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Perovskites_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logfeatures\n",
    "Perovskites_num['Diameter_nm'] = np.log10(Perovskites_num[\"Diameter_nm\"])\n",
    "Perovskites_num['Time_min'] = np.log10(Perovskites_num[\"Time_min\"])\n",
    "Perovskites_num['B2_amount_mmol'] = np.log10(Perovskites_num[\"B2_amount_mmol\"])\n",
    "Perovskites_num['Temperature_K'] = np.log10(Perovskites_num[\"Temperature_K\"])\n",
    "Perovskites_num['Bandgap'] = np.log10(Perovskites_num[\"Bandgap\"])\n",
    "Perovskites_num['Tolerance_factor_new'] = np.log10(Perovskites_num[\"Tolerance_factor_new\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ffe9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and y subsets\n",
    "x = Perovskites_num.drop(['B1_amount_mmol', 'X_amount_mmol', 'Time_min', 'Bandgap', 'Amine_amount_mmol'], axis=1)\n",
    "y = Perovskites_num[[ 'B1_amount_mmol',  'X_amount_mmol', 'Time_min','Bandgap', 'Amine_amount_mmol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70974ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "X_train_num, X_test_num, y_train_num, y_test_num = train_test_split(x, y, test_size=0.25, random_state=25) # 75% training and 25% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b33178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train_num)\n",
    "X_test_norm = scaler.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847349ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation\n",
    "def create_model(units1, units2, units3):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units1, input_dim=7, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(units2, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(units3, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(5))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c50dea",
   "metadata": {},
   "source": [
    "Optimization using Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6041496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the objective function\n",
    "def objective(params):\n",
    "    units1 = params['units1']\n",
    "    units2 = params['units2']\n",
    "    units3 = params['units3']\n",
    "    epochs = params['epochs']\n",
    "\n",
    "    # Model fitting and prediction using cross-validation\n",
    "    model = KerasRegressor(build_fn=lambda: create_model(units1, units2, units3), epochs=epochs, batch_size=32, verbose=0)\n",
    "    rkf = RepeatedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "    y_pred_train = cross_val_predict(model, X_train_norm, y_train, cv=rkf)\n",
    "\n",
    "    # Final model fitting on all training data\n",
    "    final_model = create_model(units1, units2, units3)\n",
    "    final_model.fit(X_train_norm, y_train, verbose=0, epochs=epochs, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Prediction on the test data\n",
    "    y_pred = final_model.predict(X_test_norm)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ef8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search space\n",
    "space = {\n",
    "    'units1': hp.choice('units1', [100, 200, 250]),\n",
    "    'units2': hp.choice('units2', [100, 150, 200]),\n",
    "    'units3': hp.choice('units3', [50, 80]),\n",
    "    'epochs': hp.choice('epochs', [100, 150])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of results\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab96c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e66163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best hyperparameters values\n",
    "best_values = space_eval(space, best)\n",
    "print(best_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92156c3e",
   "metadata": {},
   "source": [
    "Final model - best parameters from hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a68766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the function to create the model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=7, activation='relu'))\n",
    "    model.add(Dense(150, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(5))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the KerasRegressor model\n",
    "model = KerasRegressor(build_fn=create_model, epochs=150, batch_size=32, verbose=1)\n",
    "\n",
    "# Ajuste e previsão do modelo usando validação cruzada\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "\n",
    "# Ajuste final do modelo em todos os dados de treinamento\n",
    "final_model = create_model()\n",
    "final_model.fit(X_train_norm, y_train, verbose=1, epochs=100, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea41d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on train and test set\n",
    "y_pred_train_num = cross_val_predict(model, X_train_norm, y_train, cv=rkf)\n",
    "y_pred_num = final_model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train metrics\n",
    "MAE_train = pd.DataFrame(metrics.mean_absolute_error(y_train, y_pred_train_num, multioutput='raw_values'))\n",
    "RMSE_train = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_train, y_pred_train_num, multioutput='raw_values')))\n",
    "R2_train = pd.DataFrame(r2_score(y_train, y_pred_train_num, multioutput='raw_values'))\n",
    "\n",
    "train_metrics_nn_num = pd.concat([MAE_train,  RMSE_train, R2_train], axis='columns')\n",
    "train_metrics_nn_num.columns = ['MAE_train', 'RMSE_train','R2_train']\n",
    "print(train_metrics_nn_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17142de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test metrics\n",
    "MAE_test= pd.DataFrame(metrics.mean_absolute_error(y_test, y_pred_num, multioutput='raw_values'))\n",
    "RMSE_test = pd.DataFrame(np.sqrt(metrics.mean_squared_error(y_test, y_pred_num, multioutput='raw_values')))\n",
    "R2_test =pd.DataFrame(r2_score(y_test, y_pred_num, multioutput='raw_values'))\n",
    "\n",
    "test_metrics_nn_num = pd.concat([MAE_test, RMSE_test, R2_test], axis='columns')\n",
    "test_metrics_nn_num.columns = ['MAE_test','RMSE_test','R2_test']\n",
    "print(test_metrics_nn_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d2de3d",
   "metadata": {},
   "source": [
    "Parity plots and shap plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396726c",
   "metadata": {},
   "source": [
    "As we observed One-Hot Encoding and Hyperopt gave us the best performance, we used their metrics to the plots below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978bde3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unite train and test performance dataframes \n",
    "df_unified_nn = pd.concat([train_metrics_nn, test_metrics_nn], axis=1)\n",
    "df_unified_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b6b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store multiple figure and figure names\n",
    "file_names = []\n",
    "figs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34067e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining color palette\n",
    "colors = sns.diverging_palette(20, 220, n=200)\n",
    "cor_teste = 20\n",
    "cor_treino = 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2674d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining number of columns\n",
    "num_cols = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e14e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loop to plot parity plot for all targets (Figure 4/Figure S4-b)\n",
    "for i in range(num_cols):\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    target = y_train.columns[i]\n",
    "    \n",
    "    # Scatter plot for predictions on test data\n",
    "    ax.scatter(y_test.iloc[:, i], y_pred[:, i], color=colors[cor_teste], label='Test Set', s=30)\n",
    "    \n",
    "    # Scatter plot for predictions on training data\n",
    "    ax.scatter(y_train.iloc[:, i], y_pred_train[:, i], color=colors[cor_treino], label='Train Set', s=30)\n",
    "    \n",
    "    # Diagonal reference line\n",
    "    ax.plot([min(y_test.iloc[:, i].values), max(y_test.iloc[:, i].values)],\n",
    "            [min(y_test.iloc[:, i].values), max(y_test.iloc[:, i].values)],\n",
    "            color='black', linestyle='--')\n",
    "    \n",
    "    # Calculating validation metrics\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    mae = mean_absolute_error(y_test.iloc[:, i], y_pred[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    \n",
    "    # Add validation metrics to the plot\n",
    "    ax.text(0.04, 0.65, f'R²: {r2:.2f}\\nMAE: {mae:.2f}\\nRMSE: {rmse:.2f}', transform=ax.transAxes, fontsize=18)\n",
    "    \n",
    "    # Defining y axis label\n",
    "    ax.set_ylabel('Predicted values', fontsize=22)\n",
    "        \n",
    "    # Defining x axis label\n",
    "    ax.set_xlabel('True Values', fontsize=22)\n",
    "\n",
    "    # Changing axis character size\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        \n",
    "    # Name of the target\n",
    "    ax.set_title(f'{target}', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    # Positioning legend outside the plot\n",
    "    fig.legend(loc='center left', bbox_to_anchor=(0.95, 0.5),frameon=False, fontsize=14)\n",
    "    \n",
    "    # Resolution adjust\n",
    "    fig.set_dpi(500)\n",
    "\n",
    "    # Add figure to list\n",
    "    figs.append(fig)\n",
    "    \n",
    "    # Show the plot    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm_df = pd.DataFrame(X_train_norm)\n",
    "column_names = X_train.columns\n",
    "X_train_norm_df.columns = column_names\n",
    "#X_train_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shap plot para o modelo geral\n",
    "e_nn2 = shap.KernelExplainer(final_model.predict, X_train_norm_df)\n",
    "shap_values_nn2 = e_nn2.shap_values(X_train_norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c44d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up the SHAP values across all classes\n",
    "shap_values_combined = np.sum(shap_values_nn2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5834af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a single SHAP summary plot for all classes\n",
    "shap.summary_plot(shap_values_combined, X_train_norm_df, max_display=10, show=False)\n",
    "\n",
    "# Display the plot (FIGURE 6-c)\n",
    "shap.initjs()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a656dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar plot shap per feature per target\n",
    "e_nn = shap.KernelExplainer(final_model.predict, X_train_norm_df)\n",
    "shap_values_nn = e_nn.shap_values(X_train_norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = y.columns\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d294e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NumPy array to a pandas DataFrame\n",
    "X_train_norm_nn = pd.DataFrame(X_train_norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ea170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use index positions as feature names\n",
    "feature_names = X_train_norm_nn.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SHAP summary plot\n",
    "shap.summary_plot(shap_values_nn, X_train_norm_nn, class_names=class_names, max_display=10, feature_names=feature_names, show=False)\n",
    "\n",
    "# Display the plot (FIGURE 6-c)\n",
    "shap.initjs()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc87c3",
   "metadata": {},
   "source": [
    "### Performance comparison (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37040568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining color palette\n",
    "colors = sns.diverging_palette(20, 220, n=200)\n",
    "cor_dt = 30\n",
    "cor_rf = 199\n",
    "cor_nn = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Target Labels\n",
    "target_labels = ['B1', 'X', 'Time', 'Bandgap', 'Amine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f74d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot Configuration\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88044d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE 3\n",
    "# Plot Bar Plot for each DataFrame (FIGURE 3-a)\n",
    "plt.bar(index, RMSE_test_feat_select[(0)], bar_width, label='Random Forest', color=colors[cor_rf])\n",
    "plt.bar(index + 1 * bar_width, RMSE_test_rf[(0)], bar_width, label='Random Forest HE', color=colors[cor_dt])\n",
    "\n",
    "# Configure axis labels and legends\n",
    "plt.xlabel('Targets', fontsize=18)\n",
    "plt.ylabel('RMSE', fontsize=18)\n",
    "plt.xticks(index + bar_width, target_labels, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Remove outer box from legend\n",
    "legend = plt.legend(fontsize=14)\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d48ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Bar Plot for each DataFrame (FIGURE 3-b)\n",
    "plt.bar(index, MAE_test_feat_select[(0)], bar_width, label='Random Forest', color=colors[cor_rf])\n",
    "plt.bar(index + 1 * bar_width, MAE_test_rf[(0)], bar_width, label='Random Forest HE', color=colors[cor_dt])\n",
    "\n",
    "# Configure axis labels and legends\n",
    "plt.xlabel('Targets', fontsize=18)\n",
    "plt.ylabel('MAE', fontsize=18)\n",
    "plt.xticks(index + bar_width, target_labels, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Remove outer box from legend\n",
    "legend = plt.legend(fontsize=14)\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe88912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Bar Plot for each DataFrame (FIGURE 3-c)\n",
    "plt.bar(index, R2_test_feat_select[(0)], bar_width, label='Random Forest', color=colors[cor_rf])\n",
    "plt.bar(index + 1 * bar_width, R2_test_rf[(0)], bar_width, label='Random Forest HE', color=colors[cor_dt])\n",
    "\n",
    "# Configure axis labels and legends\n",
    "plt.xlabel('Targets', fontsize=18)\n",
    "plt.ylabel('MAE', fontsize=18)\n",
    "plt.xticks(index + bar_width, target_labels, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Remove outer box from legend\n",
    "legend = plt.legend(fontsize=14)\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c504d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Bar Plot for each DataFrame (FIGURE 5-c)\n",
    "plt.bar(index, R2_test_nn[(0)], bar_width, label='Neural Networks', color=colors[cor_nn])\n",
    "plt.bar(index + bar_width, R2_test_dt[(0)], bar_width, label='Decision Trees', color=colors[cor_dt])\n",
    "plt.bar(index + 2 * bar_width, R2_test_rf[(0)], bar_width, label='Random Forest', color=colors[cor_rf])\n",
    "\n",
    "# Configure axis labels and legends\n",
    "plt.xlabel('Targets', fontsize=18)\n",
    "plt.ylabel('R2', fontsize=18)\n",
    "plt.xticks(index + bar_width, target_labels, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Remove outer box from legend\n",
    "legend = plt.legend(fontsize=14)\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb0a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Bar Plot for each DataFrame (FIGURE 5-a)\n",
    "plt.bar(index, MAE_test_nn[(0)], bar_width, label='Neural Networks', color=colors[cor_nn])\n",
    "plt.bar(index + bar_width, MAE_test_dt[(0)], bar_width, label='Decision Trees', color=colors[cor_dt])\n",
    "plt.bar(index + 2 * bar_width, MAE_test_rf[(0)], bar_width, label='Random Forest', color=colors[cor_rf])\n",
    "\n",
    "# Configure axis labels and legends\n",
    "plt.xlabel('Targets', fontsize=18)\n",
    "plt.ylabel('MAE', fontsize=18)\n",
    "plt.xticks(index + bar_width, target_labels, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Remove outer box from legend\n",
    "legend = plt.legend(fontsize=14)\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Bar Plot for each DataFrame (FIGURE 5-b)\n",
    "plt.bar(index, RMSE_test_nn[(0)], bar_width, label='Neural Networks', color=colors[cor_nn])\n",
    "plt.bar(index + bar_width, RMSE_test_dt[(0)], bar_width, label='Decision Trees', color=colors[cor_dt])\n",
    "plt.bar(index + 2 * bar_width, RMSE_test_rf[(0)], bar_width, label='Random Forest', color=colors[cor_rf])\n",
    "\n",
    "# Configure axis labels and legends\n",
    "plt.xlabel('Targets', fontsize=18)\n",
    "plt.ylabel('RMSE', fontsize=18)\n",
    "plt.xticks(index + bar_width, target_labels, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Remove outer box from legend\n",
    "legend = plt.legend(fontsize=14)\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac73ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Bar Plot for each DataFrame (FIGURE 5-c)\n",
    "plt.bar(index, R2_test_nn[(0)], bar_width, label='Neural Networks', color=colors[cor_nn])\n",
    "plt.bar(index + bar_width, R2_test_dt[(0)], bar_width, label='Decision Trees', color=colors[cor_dt])\n",
    "plt.bar(index + 2 * bar_width, R2_test_rf[(0)], bar_width, label='Random Forest', color=colors[cor_rf])\n",
    "\n",
    "# Configure axis labels and legends\n",
    "plt.xlabel('Targets', fontsize=18)\n",
    "plt.ylabel('R2', fontsize=18)\n",
    "plt.xticks(index + bar_width, target_labels, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Remove outer box from legend\n",
    "legend = plt.legend(fontsize=14)\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861adca",
   "metadata": {},
   "source": [
    "# Model application for experimental suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f9a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of synthetic conditions for perovskite nanoparticles of Cs2AgInCl6\n",
    "\n",
    "# observe the columns in a vertical list\n",
    "print('The columns of dataframe are:')\n",
    "for col in x.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Inform the pre-selected conditions of synthesis - human input\n",
    "X_new = {\n",
    "    \n",
    "    # Inform pre-selected synthetic conditions\n",
    "    'Tolerance_factor_new':[3.79],\n",
    "    'Temperature_K':[453], \n",
    "    'A_amount_mmol':[0.71],\n",
    "    'B2_amount_mmol':[0.5],\n",
    "    'Carboxylic_acid_amount_mmol':[8.9],\n",
    "    'S_I_amount_mL':[10],\n",
    "    'Diameter_nm':[20], \n",
    "    \n",
    "    # Inform the chemicals to be used: 0 - not used, 1 - used\n",
    "    'A_source_cesium_acetate':[0],\n",
    "    'A_source_cesium_bromide':[0],\n",
    "    'A_source_cesium_carbonate':[1],\n",
    "    'A_source_potassium_carbonate':[0],\n",
    "    'A_source_rubidium_acetate':[0],\n",
    "    'A_source_rubidium_carbonate':[0],\n",
    "    \n",
    "    'B1_source_cadmium_II_acetate':[0],\n",
    "    'B1_source_cadmium_II_chloride':[0],\n",
    "    'B1_source_copper_II_acetate':[0],\n",
    "    'B1_source_copper_II_chloride':[0],\n",
    "    'B1_source_just_one_B':[0],\n",
    "    'B1_source_manganese_II_acetate':[0],\n",
    "    'B1_source_manganese_II_chloride':[0],\n",
    "    'B1_source_silver_acetate':[0],\n",
    "    'B1_source_silver_bromide':[0],\n",
    "    'B1_source_silver_nitrate':[1],\n",
    "    'B1_source_silver_oxide':[0],\n",
    "    'B1_source_sodium_acetate':[0],\n",
    "    \n",
    "    'B2_source_antimony_III_acetate':[0],\n",
    "    'B2_source_antimony_III_bromide':[0], \n",
    "    'B2_source_antimony_III_chloride':[0],\n",
    "    'B2_source_bismuth_III_acetate':[0],\n",
    "    'B2_source_bismuth_III_bromide':[0],\n",
    "    'B2_source_bismuth_III_chloride':[0],\n",
    "    'B2_source_bismuth_III_iodide':[0],\n",
    "    'B2_source_bismuth_III_neodecanoate':[0],\n",
    "    'B2_source_cadmium_II_chloride':[0],\n",
    "    'B2_source_copper_I_bromide':[0],\n",
    "    'B2_source_copper_I_chloride':[0],\n",
    "    'B2_source_copper_I_iodide':[0],\n",
    "    'B2_source_erbium_III_acetate':[0],\n",
    "    'B2_source_europium_III_chloride':[0],\n",
    "    'B2_source_germanium_II_iodide':[0],\n",
    "    'B2_source_hafnium_IV_acetylacetonate':[0],\n",
    "    'B2_source_indium_III_acetate':[0],\n",
    "    'B2_source_indium_III_bromide':[0],\n",
    "    'B2_source_indium_III_chloride':[1],\n",
    "    'B2_source_manganese_II_acetate':[0],\n",
    "    'B2_source_praseodymium_III_chloride':[0],\n",
    "    'B2_source_tin_II_bromide':[0],\n",
    "    'B2_source_tin_II_bromide':[0],\n",
    "    'B2_source_tin_II_chloride':[0],\n",
    "    'B2_source_tin_II_ethylhexanoate':[0],\n",
    "    'B2_source_tin_II_iodide':[0],\n",
    "    'B2_source_tin_II_oxalate':[0],\n",
    "    'B2_source_tin_IV_bromide':[0],\n",
    "    'B2_source_tin_IV_chloride':[0],\n",
    "    'B2_source_tin_IV_iodide':[0],\n",
    "    'B2_source_titanium_IV_isopropoxide':[0],\n",
    "    'B2_source_titanium_di_isopropoxide_bis(acetylacetonate)':[0],\n",
    "    'B2_source_ytterbium_II_iodide':[0],\n",
    "    'B2_source_zirconium_II_carbonate':[0],\n",
    "    \n",
    "    'X_source_2-ethyl_2-hexanoyl_chloride':[0],\n",
    "    'X_source_ammonium_bromide':[0],\n",
    "    'X_source_ammonium_chloride':[0],\n",
    "    'X_source_ammonium_iodide':[0],\n",
    "    'X_source_benzoyl_bromide':[0],\n",
    "    'X_source_benzoyl_chloride':[0],\n",
    "    'X_source_bromooctadecane':[0],\n",
    "    'X_source_bromotrimethylsilane':[0],\n",
    "    'X_source_chlorotrimethylsilane':[1],\n",
    "    'X_source_from_metal_salt':[0],\n",
    "    'X_source_germanium_IV_chloride':[0],\n",
    "    'X_source_indium_III_bromide':[0],\n",
    "    'X_source_indium_III_chloride':[0],\n",
    "    'X_source_indium_III_iodide':[0],\n",
    "    'X_source_manganese_chloride':[0],\n",
    "    'X_source_trimethylsilyl_iodide':[0],\n",
    "    'X_source_zinc_bromide':[0],\n",
    "    'X_source_zinc_iodide':[0],\n",
    "}\n",
    "\n",
    "X_new = pd.DataFrame(data=X_new)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56011a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding the view to visualize all of the predictors\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04829e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform logarithmic transformation of the selected conditions\n",
    "X_new['B2_amount_mmol'] = np.log10(X_new['B2_amount_mmol'])\n",
    "X_new['Temperature_K'] = np.log10(X_new['Temperature_K'])\n",
    "X_new['Tolerance_factor_new'] = np.log10(X_new['Tolerance_factor_new'])\n",
    "X_new['Diameter_nm'] = np.log10(X_new['Diameter_nm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba044783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) predict new y\n",
    "y_new=rf.predict(X_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a454a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of the predictions\n",
    "y_new = pd.DataFrame(data=y_new)\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns names to dataframe\n",
    "y_new.columns = [ 'B1_amount_mmol',  'X_amount_mmol', 'Time_min','Bandgap', 'Amine_amount_mmol']\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b890dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert logarithmic transformation\n",
    "y_new['Time_min'] = np.power(10,(y_new['Time_min']))\n",
    "y_new['Bandgap'] = np.power(10,(y_new['Bandgap']))\n",
    "X_new['Temperature_K'] = np.power(10,(X_new['Temperature_K']))\n",
    "X_new['Tolerance_factor_new'] = np.power(10,(X_new['Tolerance_factor_new']))\n",
    "X_new['B2_amount_mmol'] = np.power(10,(X_new['B2_amount_mmol']))\n",
    "X_new['Diameter_nm'] = np.power(10,(X_new['Diameter_nm']))\n",
    "\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e5bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dataframes X and Y together\n",
    "Synthesis = pd.concat([X_new,y_new], axis=1)\n",
    "Synthesis = Synthesis.loc[:,['Tolerance_factor_new','Temperature_K', 'Time_min', 'A_amount_mmol', \n",
    "                             'B1_amount_mmol','B2_amount_mmol', 'X_amount_mmol',\\\n",
    "                             'Amine_amount_mmol', 'Carboxylic_acid_amount_mmol', 'S_I_amount_mL', 'Diameter_nm', \n",
    "                             'Bandgap' ]]\n",
    "\n",
    "print(Synthesis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
